__author__ = 'Maxim K'

"""
Идея такая – попробовать для начала предсказывать двойные/одинарные связи в листах у аминокислот только на основе самих типов аминокислот и ее соседей по бета-стрэнду, на котором находится сама рассматриваемая аминокислота.
Т.е. пока не делать никаких переборов соседних стрэндов, т.е. не учитывать соседей справа и слева. Я не ожидаю, что метод будет иметь высокое качество предсказания, но это хороший старт, и можно будет сравнить результаты с существующими методами.
На основе собранных Вами данных можно попробовать, например, применить метод  Naïve Bayes.
У нас будет 5 признаков (5 features) - тип самой рассматриваемой аминокислоты, и 4 типа соседей (-1С,-2С,1С,2С). Надо построить плотности распределения для каждого из двух классов (double/single) по всем этим 5-ти признакам.
Для первого признака это будет одномерная дискретная функция плотности распределения.
Т.е. для каждого из двух классов (double/single) у Вас будет 20-ть подсчитанных вероятностей по каждому типу аминокислоты.
Вероятность подсчитывается просто – количество найденных аминокислот данного типа разделить на общее количество аминокислот в данном классе (double/single).
Для остальных четырех признаков – это уже будут двумерные дискретные плотности распределения, так как в зависимости от типа рассматриваемой аминокислоты (в позиции 0C), для каждого признака у Вас будет 20 одномерных распределений.
Т.е. фактически те же матрицы, которые Вы собрали, только в каждой клеточке надо посчитать вероятности – разделить количество найденных пар base-neib на общее количество в данном классе.
Построенные плотности распределения фактически и есть Ваша классификационная модель.
Работает она так – для нового объекта (рассматриваемой аминокислоты и 4-х ее соседей) Вы находи в построенных таблицах по всем 5-ти признакам соответствующие вероятности для класса double и перемножаете их, потом для класса single и тоже перемножаете их.
Потом смотрите какая из двух конечных вероятностей получилась больше и к тому классу и относите объект (аминокилоту).
Так как перемножение маленьких чисел может быть очень маленьким числом, то чтобы не потерять цифры далеко после запятой обычно рекомендуют заменять сами вероятности на логарифмы от этих вероятностей – числа получаются большие.
При этом перемножение заменяется сложением.
"""

import os, math

path = 'E:\\Science\\MG\Marat\\pairwise\\neib_pairwise'
path_0C = 'E:\\Science\\MG\\Marat\\server\\hist\\single.txt'

def get_strand_name(filename):
    '''
    Разделяет имя файла на части
    '''
    name = filename.replace('neib_','').split(sep='.')[0].split(sep='_')
    mult, parallel, strand = name
    return [mult, parallel, strand]


def set_normal(aa_count):
    '''
    Ставит в соответствие сочетаниям аминокислот вероятность
    '''
    count = 0
    norm_strands = {}
    aa = aa_count.split(sep='\n')[1:len(aa_count.split(sep='\n')) - 1]

    for line in aa:
        count += int(line.split()[2])

    for line in aa:
        if line.split()[0] in norm_strands.keys():
            norm_strands[line.split()[0]][line.split()[1]] = math.log2(int(line.split()[2]) / count)
        else:
            norm_strands[line.split()[0]] = {line.split()[1]: math.log2(int(line.split()[2]) / count)}

    return norm_strands

def set_normal_0(aa_count):
    '''
    Ставит в соответствие аминокислотам вероятность
    '''
    count = 0
    norm_strands = {}
    aa = aa_count.split(sep='\n')[1:len(aa_count.split(sep='\n')) - 1]

    for line in aa:
        count += int(line.split()[1])

    for line in aa:
        norm_strands[line.split()[0]] = math.log2(int(line.split()[1]) / count)

    return norm_strands

prob = dict()

for dirname, dirnames, filenames in os.walk(path):
    for filename in filenames:
        file = open(os.path.join(dirname, filename), 'r').read()
        strand_name = get_strand_name(filename)
        aa_norm = set_normal(file)
        prob[strand_name[2]] = set_normal(file)

prob['0C'] = set_normal_0(open(path_0C, 'r').read())

print()